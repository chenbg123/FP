{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1576898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "69ae408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf = np.load('feature_extraction/X_train_tf.npy', allow_pickle=True)\n",
    "x_train_count = np.load('feature_extraction/X_train_count.npy', allow_pickle=True)\n",
    "\n",
    "\n",
    "x_test_tf = np.load('feature_extraction/X_test_tf.npy', allow_pickle=True)\n",
    "x_test_count = np.load('feature_extraction/X_test_count.npy', allow_pickle=True)\n",
    "\n",
    "y_train = np.load('feature_extraction/y_train.npy', allow_pickle=True)\n",
    "y_test = np.load('feature_extraction/y_test.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0182ac5",
   "metadata": {},
   "source": [
    "# Build machine learning modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7c2d61f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables to store the metrics\n",
    "metrics_data = {\n",
    "    \"Model\": [],\n",
    "    \"Feature Extraction\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1 Score\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3768197f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for RF with TF-IDF for (1, 1) range gram:\n",
      "Accuracy: 0.913239267487241\n",
      "Precision: 0.8891774891774892\n",
      "Recall: 0.8644781144781145\n",
      "F1 Score: 0.8766538625693555\n",
      "\n",
      "Metrics for RF with TF-IDF for (1, 2) range gram:\n",
      "Accuracy: 0.9156409486640649\n",
      "Precision: 0.9031111111111111\n",
      "Recall: 0.8552188552188552\n",
      "F1 Score: 0.8785127539991353\n",
      "\n",
      "Metrics for RF with TF-IDF for (1, 3) range gram:\n",
      "Accuracy: 0.9168417892524767\n",
      "Precision: 0.9020300088261254\n",
      "Recall: 0.8602693602693603\n",
      "F1 Score: 0.8806548901335631\n",
      "\n",
      "Metrics for RF with TF-IDF for (1, 4) range gram:\n",
      "Accuracy: 0.9159411588111678\n",
      "Precision: 0.901060070671378\n",
      "Recall: 0.8585858585858586\n",
      "F1 Score: 0.8793103448275861\n",
      "\n",
      "Metrics for RF with Count Vectorization:\n",
      "Accuracy: 0.9084359051335935\n",
      "Precision: 0.906163753449862\n",
      "Recall: 0.8291245791245792\n",
      "F1 Score: 0.8659340659340661\n",
      "\n",
      "Metrics for LR with TF-IDF for (1, 1) range gram:\n",
      "Accuracy: 0.9198438907235065\n",
      "Precision: 0.8866498740554156\n",
      "Recall: 0.8888888888888888\n",
      "F1 Score: 0.8877679697351828\n",
      "\n",
      "Metrics for LR with TF-IDF for (1, 2) range gram:\n",
      "Accuracy: 0.9144401080756529\n",
      "Precision: 0.9123287671232877\n",
      "Recall: 0.8409090909090909\n",
      "F1 Score: 0.8751642575558476\n",
      "\n",
      "Metrics for LR with TF-IDF for (1, 3) range gram:\n",
      "Accuracy: 0.9081356949864905\n",
      "Precision: 0.9224137931034483\n",
      "Recall: 0.8106060606060606\n",
      "F1 Score: 0.8629032258064515\n",
      "\n",
      "Metrics for LR with TF-IDF for (1, 4) range gram:\n",
      "Accuracy: 0.9012308616031222\n",
      "Precision: 0.9231527093596059\n",
      "Recall: 0.7887205387205387\n",
      "F1 Score: 0.8506581933726737\n",
      "\n",
      "Metrics for LR with Count Vectorization:\n",
      "Accuracy: 0.9207445211648154\n",
      "Precision: 0.8743922204213939\n",
      "Recall: 0.9082491582491582\n",
      "F1 Score: 0.8909991742361684\n",
      "\n",
      "Metrics for DT with TF-IDF for (1, 1) range gram:\n",
      "Accuracy: 0.8429900930651456\n",
      "Precision: 0.7750206782464847\n",
      "Recall: 0.7887205387205387\n",
      "F1 Score: 0.7818105965790573\n",
      "\n",
      "Metrics for DT with TF-IDF for (1, 2) range gram:\n",
      "Accuracy: 0.8399879915941159\n",
      "Precision: 0.7791986359761296\n",
      "Recall: 0.7693602693602694\n",
      "F1 Score: 0.7742481999152901\n",
      "\n",
      "Metrics for DT with TF-IDF for (1, 3) range gram:\n",
      "Accuracy: 0.8357850495346743\n",
      "Precision: 0.7779705117085863\n",
      "Recall: 0.7550505050505051\n",
      "F1 Score: 0.7663391712943187\n",
      "\n",
      "Metrics for DT with TF-IDF for (1, 4) range gram:\n",
      "Accuracy: 0.8294806364455118\n",
      "Precision: 0.7631578947368421\n",
      "Recall: 0.7567340067340067\n",
      "F1 Score: 0.7599323753169906\n",
      "\n",
      "Metrics for DT with Count Vectorization:\n",
      "Accuracy: 0.8507955568898229\n",
      "Precision: 0.8012205754141238\n",
      "Recall: 0.7735690235690236\n",
      "F1 Score: 0.7871520342612419\n",
      "\n",
      "Metrics for NB with TF-IDF for (1, 1) range gram:\n",
      "Accuracy: 0.8829180426298409\n",
      "Precision: 0.9473094170403588\n",
      "Recall: 0.7112794612794613\n",
      "F1 Score: 0.8125\n",
      "\n",
      "Metrics for NB with TF-IDF for (1, 2) range gram:\n",
      "Accuracy: 0.8240768537976584\n",
      "Precision: 0.9823717948717948\n",
      "Recall: 0.515993265993266\n",
      "F1 Score: 0.6766004415011038\n",
      "\n",
      "Metrics for NB with TF-IDF for (1, 3) range gram:\n",
      "Accuracy: 0.8102671870309216\n",
      "Precision: 0.9826388888888888\n",
      "Recall: 0.4764309764309764\n",
      "F1 Score: 0.6417233560090703\n",
      "\n",
      "Metrics for NB with TF-IDF for (1, 4) range gram:\n",
      "Accuracy: 0.8012608826178325\n",
      "Precision: 0.987037037037037\n",
      "Recall: 0.44865319865319864\n",
      "F1 Score: 0.6168981481481481\n",
      "\n",
      "Metrics for NB with Count Vectorization:\n",
      "Accuracy: 0.9147403182227559\n",
      "Precision: 0.8971880492091389\n",
      "Recall: 0.8594276094276094\n",
      "F1 Score: 0.8779019776440241\n",
      "\n",
      "Metrics for SVC with TF-IDF for (1, 1) range gram:\n",
      "Accuracy: 0.9381567096967878\n",
      "Precision: 0.9078073089700996\n",
      "Recall: 0.92003367003367\n",
      "F1 Score: 0.9138795986622072\n",
      "\n",
      "Metrics for SVC with TF-IDF for (1, 2) range gram:\n",
      "Accuracy: 0.9318522966076254\n",
      "Precision: 0.918918918918919\n",
      "Recall: 0.8872053872053872\n",
      "F1 Score: 0.9027837259100643\n",
      "\n",
      "Metrics for SVC with TF-IDF for (1, 3) range gram:\n",
      "Accuracy: 0.9252476733713599\n",
      "Precision: 0.9272065514103731\n",
      "Recall: 0.8577441077441077\n",
      "F1 Score: 0.8911237428946217\n",
      "\n",
      "Metrics for SVC with TF-IDF for (1, 4) range gram:\n",
      "Accuracy: 0.9189432602821975\n",
      "Precision: 0.9305816135084428\n",
      "Recall: 0.835016835016835\n",
      "F1 Score: 0.8802129547471161\n",
      "\n",
      "Metrics for SVC with Count Vectorization:\n",
      "Accuracy: 0.9108375863104173\n",
      "Precision: 0.8549800796812749\n",
      "Recall: 0.9031986531986532\n",
      "F1 Score: 0.8784281620957838\n",
      "\n",
      "Metrics for GB with TF-IDF for (1, 1) range gram:\n",
      "Accuracy: 0.8580006004202942\n",
      "Precision: 0.8743455497382199\n",
      "Recall: 0.7028619528619529\n",
      "F1 Score: 0.7792813812412507\n",
      "\n",
      "Metrics for GB with TF-IDF for (1, 2) range gram:\n",
      "Accuracy: 0.8586010207145002\n",
      "Precision: 0.8624873609706775\n",
      "Recall: 0.718013468013468\n",
      "F1 Score: 0.7836472209462563\n",
      "\n",
      "Metrics for GB with TF-IDF for (1, 3) range gram:\n",
      "Accuracy: 0.8577003902731912\n",
      "Precision: 0.8562874251497006\n",
      "Recall: 0.7222222222222222\n",
      "F1 Score: 0.7835616438356166\n",
      "\n",
      "Metrics for GB with TF-IDF for (1, 4) range gram:\n",
      "Accuracy: 0.8555989192434704\n",
      "Precision: 0.8552763819095477\n",
      "Recall: 0.7163299663299664\n",
      "F1 Score: 0.7796610169491525\n",
      "\n",
      "Metrics for GB with Count Vectorization:\n",
      "Accuracy: 0.8555989192434704\n",
      "Precision: 0.7895167895167895\n",
      "Recall: 0.8114478114478114\n",
      "F1 Score: 0.8003320880033208\n",
      "\n",
      "Metrics for KNN with TF-IDF for (1, 1) range gram:\n",
      "Accuracy: 0.8946262383668568\n",
      "Precision: 0.8981921979067554\n",
      "Recall: 0.7946127946127947\n",
      "F1 Score: 0.84323358642251\n",
      "\n",
      "Metrics for KNN with TF-IDF for (1, 2) range gram:\n",
      "Accuracy: 0.8934253977784449\n",
      "Precision: 0.8955365622032289\n",
      "Recall: 0.7937710437710438\n",
      "F1 Score: 0.8415885765283356\n",
      "\n",
      "Metrics for KNN with TF-IDF for (1, 3) range gram:\n",
      "Accuracy: 0.8946262383668568\n",
      "Precision: 0.8974358974358975\n",
      "Recall: 0.7954545454545454\n",
      "F1 Score: 0.8433734939759037\n",
      "\n",
      "Metrics for KNN with TF-IDF for (1, 4) range gram:\n",
      "Accuracy: 0.89192434704293\n",
      "Precision: 0.8973128598848369\n",
      "Recall: 0.7870370370370371\n",
      "F1 Score: 0.8385650224215246\n",
      "\n",
      "Metrics for KNN with Count Vectorization:\n",
      "Accuracy: 0.784449114380066\n",
      "Precision: 0.7011986301369864\n",
      "Recall: 0.6893939393939394\n",
      "F1 Score: 0.6952461799660442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the models\n",
    "models = [\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    LogisticRegression(random_state=42, max_iter=1000),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    MultinomialNB(),\n",
    "    SVC(random_state=42),\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "# Define the model names\n",
    "model_names = [\"RF\", \"LR\", \"DT\", \"NB\", \"SVC\", \"GB\", \"KNN\"]\n",
    "\n",
    "# Define the ngram_ranges corresponding to the x_data\n",
    "ngram_ranges = [(1, 1), (1, 2), (1, 3), (1, 4)]\n",
    "\n",
    "# Iterate over models, x_data, and ngram_ranges\n",
    "for model, model_name in zip(models, model_names):\n",
    "    for x_train, x_test, ngram_range in zip(x_train_tf, x_test_tf, ngram_ranges):\n",
    "        # Fit the model on the training data\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        # Predict on the test data\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        # Append the metrics to the data dictionary\n",
    "        metrics_data[\"Model\"].append(model_name)\n",
    "        metrics_data[\"Feature Extraction\"].append(\"TF-IDF\" + str(ngram_range))\n",
    "        metrics_data[\"Accuracy\"].append(acc)\n",
    "        metrics_data[\"Precision\"].append(precision)\n",
    "        metrics_data[\"Recall\"].append(recall)\n",
    "        metrics_data[\"F1 Score\"].append(f1)\n",
    "\n",
    "        # Print evaluation metrics\n",
    "        print(f\"Metrics for {model_name} with TF-IDF for {ngram_range} range gram:\")\n",
    "        print(\"Accuracy:\", acc)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1 Score:\", f1)\n",
    "        print()\n",
    "\n",
    "    # Fit the model on the Count Vectorization data\n",
    "    model.fit(x_train_count, y_train)\n",
    "    y_pred_count = model.predict(x_test_count)\n",
    "    acc_count = accuracy_score(y_test, y_pred_count)\n",
    "    precision_count = precision_score(y_test, y_pred_count)\n",
    "    recall_count = recall_score(y_test, y_pred_count)\n",
    "    f1_count = f1_score(y_test, y_pred_count)\n",
    "\n",
    "    # Append the metrics for Count Vectorization\n",
    "    metrics_data[\"Model\"].append(model_name)\n",
    "    metrics_data[\"Feature Extraction\"].append(\"Count Vectorization\")\n",
    "    metrics_data[\"Accuracy\"].append(acc_count)\n",
    "    metrics_data[\"Precision\"].append(precision_count)\n",
    "    metrics_data[\"Recall\"].append(recall_count)\n",
    "    metrics_data[\"F1 Score\"].append(f1_count)\n",
    "\n",
    "    # Print evaluation metrics for Count Vectorization\n",
    "    print(f\"Metrics for {model_name} with Count Vectorization:\")\n",
    "    print(\"Accuracy:\", acc_count)\n",
    "    print(\"Precision:\", precision_count)\n",
    "    print(\"Recall:\", recall_count)\n",
    "    print(\"F1 Score:\", f1_count)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "36772d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the metrics to a file or data structure\n",
    "import pandas as pd\n",
    "df_metrics = pd.DataFrame(metrics_data)\n",
    "df_metrics.to_csv(\"metrics.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
